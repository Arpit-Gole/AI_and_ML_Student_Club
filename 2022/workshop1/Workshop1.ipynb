{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35305dd7-5494-45fd-94ab-81b94dba8868",
   "metadata": {},
   "source": [
    "# Workshop 1 - TF-IDF\n",
    "\n",
    "This notebook implements TF-IDF from ground up to build the represent the word/phrase/sentence/paragraph by vector semantic.<br/>\n",
    "\n",
    "<b>Author: </b> Arpit Gole <br/>\n",
    "<b>Contact on: </b> <a href=\"mailto:arpit.gole@adelaide.edu.au\">arpit.gole@adelaide.edu.au</a> <br/>\n",
    "<b>Created on: </b> 27/08/22 <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96126048-bb0b-4944-832c-03b93bd55e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import  word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b90a9534-9b44-46b7-99e0-31dd934eacb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\arpit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notebook configs \n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930b5329-ee8c-44cd-988e-bfaace853eaf",
   "metadata": {},
   "source": [
    "## Reading/Generating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c54140a4-94a8-4e87-b81e-d0ffbc10a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the data\n",
    "def read_txt(file):\n",
    "    with open(file, 'r', encoding=\"utf8\") as fp:\n",
    "        return fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de089d13-2135-4e4b-a200-65befb558f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Let's check if the data is already present\n",
    "if not os.path.exists('medium_doc.txt') or not os.path.exists('large_doc.txt'):\n",
    "    \n",
    "    # Generating the data - essentially duplicating the original text n times\n",
    "    for name, loop_num in [('medium_doc.txt', 10), ('large_doc.txt', 25)]:\n",
    "        for _ in tqdm(range(loop_num), desc=f\"Generating data for {name}\"):\n",
    "            with open(name, 'a+', encoding=\"utf8\") as fp:\n",
    "                fp.writelines(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77c261c1-6147-4631-b2bb-61b6c6c24057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "# Different files to read are:\n",
    "# 1. doc.txt\n",
    "# 2. medium_doc.txt\n",
    "# 3. large_doc.txt\n",
    "text = read_txt('doc.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a9b570-adde-4bf1-8154-3bfb4a601942",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04a6fb32-9c75-40d1-ad6d-442c0ef371a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14.1 s\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Preprocessing the text data\n",
    "sentences = []\n",
    " \n",
    "for sent in text:\n",
    "    x = [i.lower() for  i in word_tokenize(sent) if i.isalpha()]\n",
    "    sentences.append(x)\n",
    "\n",
    "# Removing the empty lines (which are read as empty sentences)\n",
    "sentences = [sentence for sentence in sentences if len(sentence) != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4271e2cd-48c1-408a-a7f2-c8101786d723",
   "metadata": {},
   "source": [
    "<b>Note:</b> Here, we are considering each sentence as a document. Whereas, in real world problem each document can a complete text file, movie review, basically any corpus of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6359796-e4d4-4a1b-ad6f-f39bb0de98f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a series.\n",
    "X_train = pd.Series(sentences, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f3f0149-c0e3-490a-aecc-72b97cd066e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [the, project, gutenberg, ebook, of, the, holl...\n",
       "1    [this, ebook, is, for, the, use, of, anyone, a...\n",
       "2    [most, other, parts, of, the, world, at, no, c...\n",
       "3    [whatsoever, you, may, copy, it, give, it, awa...\n",
       "4    [of, the, project, gutenberg, license, include...\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data visualisation\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1e2453-6d87-420c-8c37-5c28b10eca1f",
   "metadata": {},
   "source": [
    "## TF-IDF Algorithm using Inverted File."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b1fa3dd-d980-431f-8647-3fdfa3bdb496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing TF part: 156151it [00:00, 167926.20it/s]\n",
      "Computing IDF part: 100%|██████████████████████████████████████████████████████████| 2032/2032 [01:00<00:00, 33.43it/s]\n",
      "Computing Inverted File using TF-IDF: 100%|████████████████████████████████| 156151/156151 [00:00<00:00, 337923.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 2s\n",
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# TF-IDF Implementation using Inverted File.\n",
    "\n",
    "# Total number of documents in the set.\n",
    "N = len(X_train)\n",
    "\n",
    "# Global storing variables\n",
    "tf = []\n",
    "idf = {}\n",
    "inverted_file = defaultdict(list)\n",
    "vocab = set()\n",
    "\n",
    "# TF Part\n",
    "for doc_num, val in tqdm(zip(X_train.index, X_train), desc=\"Computing TF part\"):\n",
    "    temp = {}\n",
    "\n",
    "    for k, v in Counter(val).items():\n",
    "        # Formula given in the slides\n",
    "        temp[k] = 1 + math.log10(v)\n",
    "        vocab.add(k)\n",
    "\n",
    "    tf.append((doc_num, temp))\n",
    "\n",
    "# IDF part\n",
    "for word in tqdm(vocab, desc=\"Computing IDF part\"):\n",
    "    word_doc_count = 0\n",
    "\n",
    "    for val in X_train:\n",
    "        if word in val:\n",
    "            word_doc_count += 1\n",
    "    \n",
    "    # Formula given in the slides\n",
    "    idf[word] = N / word_doc_count\n",
    "\n",
    "# Putting it together - building Inverted File\n",
    "for doc_num, val in tqdm(tf, desc=\"Computing Inverted File using TF-IDF\"):\n",
    "    for k, v in val.items():\n",
    "        tf_idf = v * idf[k]\n",
    "        inverted_file[k].append((doc_num, tf_idf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cd891c-6586-44c1-8fc6-256c1aa121dd",
   "metadata": {},
   "source": [
    "## Searching a word in the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47673532-db84-44df-a445-7a20f417ac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_word = 'hollow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3be7208a-38be-46b2-a73e-f25a2bf1bfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 27.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1800"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 1. Using the normal way using a loop. \n",
    "# Time complexity is O(n).\n",
    "len([sentence for sentence in sentences if search_word in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "281456a8-36d7-4b6f-b65e-282e55b896d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1.01 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 2. Using te TF-IDF.\n",
    "# Time complexity is O(1).\n",
    "docs_priority = defaultdict(int)\n",
    "\n",
    "inverted_file_values = inverted_file[search_word]\n",
    "                \n",
    "if inverted_file_values != []:\n",
    "    for doc_num, tfidf in inverted_file_values:\n",
    "\n",
    "        docs_priority[doc_num] += tfidf   # Update the values \n",
    "else:\n",
    "    print('Word is not present in any document') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1ea235-c8e1-4e58-9f54-01063865e64b",
   "metadata": {},
   "source": [
    "THE END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aabdb00-bc5e-4e5d-9ade-a39cb8a0754e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
