{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Fashion-MNIST\n",
    "\n",
    "Now it's your turn to build and train a neural network. You'll be using the [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist), a drop-in replacement for the MNIST dataset. MNIST is actually quite trivial with neural networks where you can easily achieve better than 97% accuracy. Fashion-MNIST is a set of 28x28 greyscale images of clothes. It's more complex than MNIST, so it's a better representation of the actual performance of your network, and a better representation of datasets you'll use in the real world.\n",
    "\n",
    "<img src='assets/fashion-mnist-sprite.png' width=500px>\n",
    "\n",
    "In this notebook, you'll build your own neural network. For the most part, you could just copy and paste the code from Part 3, but you wouldn't be learning. It's important for you to write the code yourself and get it to work. Feel free to consult the previous notebooks though as you work through this.\n",
    "\n",
    "First off, let's load the dataset through torchvision.\n",
    "First off, let's load the dataset through torchvision.\n",
    "\n",
    "\n",
    "# Workshop 2 - Classifying Fashion-MNIST with PyTorch\n",
    "\n",
    "\n",
    "This notebook implements TF-IDF from ground up to build and represent the word/phrase/sentence/paragraph by vector semantic.<br/>\n",
    "\n",
    "[![Open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Arpit-Gole/AI_and_ML_Student_Club/blob/main/2022/workshop2/Workshop2.ipynb)\n",
    "\n",
    "<b>Author: </b> Arpit Gole <br/>\n",
    "<b>Contact on: </b> <a href=\"mailto:arpit.gole@adelaide.edu.au\">arpit.gole@adelaide.edu.au</a> <br/>\n",
    "<b>Created on: </b> 27/08/22 <br/>\n",
    "<b>Last Modified on: </b> 07/09/22 <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import helper\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see one of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "Here you should define your network. As with MNIST, each image is 28x28 which is a total of 784 pixels, and there are 10 classes. You should include at least one hidden layer. We suggest you use ReLU activations for the layers and to return the logits or log-softmax from the forward pass. It's up to you how many layers you add and the size of those layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your network architecture here\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network\n",
    "\n",
    "Now you should create your network and train it. First you'll want to define [the criterion](http://pytorch.org/docs/master/nn.html#loss-functions) (something like `nn.CrossEntropyLoss` or `nn.NLLLoss`) and [the optimizer](http://pytorch.org/docs/master/optim.html) (typically `optim.SGD` or `optim.Adam`).\n",
    "\n",
    "Then write the training code. Remember the training pass is a fairly straightforward process:\n",
    "\n",
    "* Make a forward pass through the network to get the logits \n",
    "* Use the logits to calculate the loss\n",
    "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
    "* Take a step with the optimizer to update the weights\n",
    "\n",
    "By adjusting the hyperparameters (hidden units, learning rate, etc), you should be able to get the training loss below 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the network, define the criterion and optimizer\n",
    "model = Classifier()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 283.4510831311345\n",
      "Training loss: 274.7842669263482\n",
      "Training loss: 267.907463490963\n",
      "Training loss: 258.2156918346882\n",
      "Training loss: 251.79347000271082\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train the network here\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mmatplotlib\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39minline\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mInlineBackend.figure_format = \u001b[39m\u001b[39m'\u001b[39m\u001b[39mretina\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mhelper\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2309\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2307\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2308\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2309\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2310\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/IPython/core/magics/pylab.py:99\u001b[0m, in \u001b[0;36mPylabMagics.matplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAvailable matplotlib backends: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m backends_list)\n\u001b[1;32m     98\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     gui, backend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshell\u001b[39m.\u001b[39;49menable_matplotlib(args\u001b[39m.\u001b[39;49mgui\u001b[39m.\u001b[39;49mlower() \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(args\u001b[39m.\u001b[39;49mgui, \u001b[39mstr\u001b[39;49m) \u001b[39melse\u001b[39;49;00m args\u001b[39m.\u001b[39;49mgui)\n\u001b[1;32m    100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_show_matplotlib_backend(args\u001b[39m.\u001b[39mgui, backend)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3458\u001b[0m, in \u001b[0;36mInteractiveShell.enable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   3437\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39menable_matplotlib\u001b[39m(\u001b[39mself\u001b[39m, gui\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   3438\u001b[0m     \u001b[39m\"\"\"Enable interactive matplotlib and inline figure support.\u001b[39;00m\n\u001b[1;32m   3439\u001b[0m \n\u001b[1;32m   3440\u001b[0m \u001b[39m    This takes the following steps:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3456\u001b[0m \u001b[39m        display figures inline.\u001b[39;00m\n\u001b[1;32m   3457\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3458\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib_inline\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_inline\u001b[39;00m \u001b[39mimport\u001b[39;00m configure_inline_support\n\u001b[1;32m   3460\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m pylabtools \u001b[39mas\u001b[39;00m pt\n\u001b[1;32m   3461\u001b[0m     gui, backend \u001b[39m=\u001b[39m pt\u001b[39m.\u001b[39mfind_gui_and_backend(gui, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpylab_gui_select)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/matplotlib_inline/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m backend_inline, config  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.1.6\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/matplotlib_inline/backend_inline.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"A matplotlib backend for publishing figures via display_data\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Copyright (c) IPython Development Team.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Distributed under the terms of the BSD 3-Clause License.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m colors\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackends\u001b[39;00m \u001b[39mimport\u001b[39;00m backend_agg\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "\n",
    "# Test out your network!\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[1]\n",
    "\n",
    "# TODO: Calculate the class probabilities (softmax) for img\n",
    "ps = torch.exp(model(img))\n",
    "\n",
    "# Plot the image and probabilities\n",
    "helper.view_classify(img, ps, version='Fashion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
